{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple BiLSTM.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMizcL6JFe2UmLgNSpTkJq+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpk-a7/Deep-learning/blob/main/simple_BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w6jfzp80sXrS"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from builtins import range, input\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU, Bidirectional\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg8QUOyXs18K",
        "outputId": "5d6d4ea7-278c-49a6-e52e-b179f9d45f3c"
      },
      "source": [
        "T = 8\n",
        "D = 2\n",
        "M = 3\n",
        "X = np.random.randn(1,T,D)\n",
        "X"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-0.6745193 ,  0.6360516 ],\n",
              "        [ 0.66586977,  0.58133706],\n",
              "        [ 0.04256627, -0.5986572 ],\n",
              "        [-0.76017067,  1.18155085],\n",
              "        [ 0.31534396,  0.03898344],\n",
              "        [ 0.35204065, -2.17628729],\n",
              "        [ 1.21068711, -1.0469937 ],\n",
              "        [-1.94783278, -0.12350101]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AJRkeB4as_uQ",
        "outputId": "42447c43-6a25-44d8-b6ec-dd5816ff3bd7"
      },
      "source": [
        "# return_sequence = True\n",
        "input_ = Input(shape=(T,D))\n",
        "rnn = Bidirectional(LSTM(M, return_state=True, return_sequences=True))\n",
        "x = rnn(input_)\n",
        "\n",
        "model = Model(inputs= input_, outputs=x)\n",
        "o,h1,c1,h2,c2 = model.predict(X)\n",
        "print(\"o:\",o)\n",
        "print(\"o shape:\",o.shape)\n",
        "print(\"h1:\",h1)\n",
        "print(\"c1:\",c1)\n",
        "print(\"h2:\",h2)\n",
        "print(\"c2:\",c2)\n",
        "\n",
        "\"\"\"\n",
        "> output[-1][:3] == h1\n",
        "> output[0][3:] == h2\n",
        "\"\"\""
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "o: [[[ 0.14731355  0.00211654 -0.06773032  0.04561712  0.06563924\n",
            "   -0.0671422 ]\n",
            "  [ 0.12267513 -0.1749671  -0.05766064  0.11997465 -0.00602724\n",
            "    0.08217933]\n",
            "  [-0.00584082 -0.02159501 -0.03147262  0.01474291  0.04868564\n",
            "    0.00592009]\n",
            "  [ 0.1853778  -0.08503083 -0.08524734  0.03770106  0.1284917\n",
            "   -0.04195866]\n",
            "  [ 0.13650246 -0.12735102 -0.10908104  0.09124467  0.01029819\n",
            "    0.17781505]\n",
            "  [-0.05665368  0.09060556  0.04303955  0.03955382  0.02270232\n",
            "    0.0915746 ]\n",
            "  [-0.19420207  0.09038375  0.17662862  0.06716296  0.08136498\n",
            "    0.0636468 ]\n",
            "  [ 0.11622357  0.21477622 -0.0419955  -0.08358393  0.22922865\n",
            "   -0.12408707]]]\n",
            "o shape: (1, 8, 6)\n",
            "h1: [[ 0.11622357  0.21477622 -0.0419955 ]]\n",
            "c1: [[ 0.3111561   0.6262331  -0.12006184]]\n",
            "h2: [[ 0.04561712  0.06563924 -0.0671422 ]]\n",
            "c2: [[ 0.0971456   0.10547734 -0.10415222]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TXQPLpa4tucF",
        "outputId": "65a05af8-c85e-426a-da0f-d43c064ba2e8"
      },
      "source": [
        "# return_sequence = False\n",
        "input_1 = Input(shape=(T,D))\n",
        "rnn1 = Bidirectional(LSTM(M, return_state=True, return_sequences=False))\n",
        "x1 = rnn1(input_1)\n",
        "\n",
        "model1 = Model(inputs= input_1, outputs=x1)\n",
        "o1,h11,c11,h21,c21 = model1.predict(X)\n",
        "print(\"o:\",o1)\n",
        "print(\"o shape:\",o1.shape)\n",
        "print(\"h1:\",h11)\n",
        "print(\"c1:\",c11)\n",
        "print(\"h2:\",h21)\n",
        "print(\"c2:\",c21)\n",
        "\n",
        "\"\"\"\n",
        "> output[0][:3] == h1\n",
        "> output[0][3:] == h2\n",
        "\"\"\""
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7efd891e4b00> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "o: [[0.23665865 0.39235148 0.08905505 0.03871855 0.24557176 0.02295763]]\n",
            "o shape: (1, 6)\n",
            "h1: [[0.23665865 0.39235148 0.08905505]]\n",
            "c1: [[0.316394  0.5862307 0.1313714]]\n",
            "h2: [[0.03871855 0.24557176 0.02295763]]\n",
            "c2: [[0.07869172 0.40682688 0.05008529]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}