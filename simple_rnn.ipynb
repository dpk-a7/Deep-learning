{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_rnn.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNqnv9Gky3xCHdMukJA3PVp",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dpk-a7/Deep-learning/blob/main/simple_rnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2VPSLol0cfFK"
      },
      "source": [
        "from __future__ import print_function, division\n",
        "from builtins import range, input\n",
        "from keras.models import Model\n",
        "from keras.layers import Input, LSTM, GRU\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D45twOHaE-ug"
      },
      "source": [
        "T = 8 #sequence length\n",
        "D = 2 #input dimensionality\n",
        "M = 3 #hiddenlayer size"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8CKbRiHFSb3",
        "outputId": "686d847c-0789-4381-f61f-2d82a5cfeb8d"
      },
      "source": [
        "X = np.random.randn(1,T,D)\n",
        "X"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[ 1.03163825, -0.71953098],\n",
              "        [ 0.00853781,  0.7402735 ],\n",
              "        [-0.20452175, -0.66004121],\n",
              "        [-1.55782345, -0.07324312],\n",
              "        [-0.02573443,  0.97291388],\n",
              "        [-0.95675742,  0.27499966],\n",
              "        [ 1.6366397 , -1.19509644],\n",
              "        [-0.39645626, -0.75070355]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7TintadFVwI"
      },
      "source": [
        "def lstm1():\n",
        "  input_ = Input(shape=(T,D))\n",
        "  rnn = LSTM(M, return_state=True)\n",
        "  x = rnn(input_)\n",
        "  model = Model(inputs = input_, outputs = x)\n",
        "  o,h,c = model.predict(X)\n",
        "  print(\"output(o): \",o)\n",
        "  print(\"hidden(h): \",h)\n",
        "  print(\"cell state(c): \",c)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TmxVervwHAex",
        "outputId": "ec2ef486-eedc-42e9-a3df-5296a3e15b34"
      },
      "source": [
        "lstm1()# o is equal to h"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output(o):  [[-0.02642967 -0.08177073 -0.00889597]]\n",
            "hidden(h):  [[-0.02642967 -0.08177073 -0.00889597]]\n",
            "cell state(c):  [[-0.05651069 -0.16937327 -0.01504447]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s4sYL-G8HCgf"
      },
      "source": [
        "def lstm2():\n",
        "  input_ = Input(shape=(T,D))\n",
        "  rnn = LSTM(M, return_state= True, return_sequences=True)\n",
        "  # rnn = GRU(M, return_state = True)\n",
        "  x = rnn(input_)\n",
        "  model = Model(inputs = input_, outputs = x)\n",
        "  o,h,c = model.predict(X)\n",
        "  print(\"output(o): \",o)\n",
        "  print(\"hidden(h): \",h)\n",
        "  print(\"cell state(c): \",c)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jMQh_fgGHPUc",
        "outputId": "e20f39f0-21be-43f8-8ded-c1471d5ffbcb"
      },
      "source": [
        "lstm2() #o is of len 8 and the last index is equal to h"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "output(o):  [[[ 0.03619287  0.00510833 -0.16600923]\n",
            "  [-0.07060698 -0.10658424 -0.02851453]\n",
            "  [ 0.04532725  0.03341681 -0.05812428]\n",
            "  [ 0.15506193  0.1303978   0.10059753]\n",
            "  [-0.05105373  0.00120459  0.22447072]\n",
            "  [-0.04112259  0.03010226  0.21203357]\n",
            "  [ 0.04071012  0.01738683 -0.00436735]\n",
            "  [ 0.16055512  0.10387123 -0.03506802]]]\n",
            "hidden(h):  [[ 0.16055512  0.10387123 -0.03506802]]\n",
            "cell state(c):  [[ 0.28125465  0.26425835 -0.07813565]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SsUOhuttJVn4"
      },
      "source": [
        "* h and c represents the final hidden states of the lstm.\n",
        "* h and c are the hidden state and the cell state at the final time step"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02NtGpdAHtes"
      },
      "source": [
        "def gru1():\n",
        "  input_ = Input(shape = (T,D))\n",
        "  rnn = GRU(M, return_state = True)\n",
        "  x = rnn(input_)\n",
        "  model = Model(inputs = input_, outputs = x)\n",
        "  o,h = model.predict(X)\n",
        "  print(\"output(o): \",o)\n",
        "  print(\"hidden(h): \",h)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eiRcU-fRIQFP",
        "outputId": "a81dbfb9-80ec-4511-dcab-d31dcd00aa5e"
      },
      "source": [
        "gru1() #o is same as h"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f4429ba5830> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "output(o):  [[-0.28984827  0.045361    0.17573981]]\n",
            "hidden(h):  [[-0.28984827  0.045361    0.17573981]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K_qWdbtRIRiH"
      },
      "source": [
        "def gru2():\n",
        "  input_ = Input(shape = (T,D))\n",
        "  rnn = GRU(M, return_state = True, return_sequences=True)\n",
        "  x = rnn(input_)\n",
        "  model = Model(inputs = input_, outputs = x)\n",
        "  o,h = model.predict(X)\n",
        "  print(\"output(o): \",o)\n",
        "  print(\"hidden(h): \",h)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pix6G3MsId4s",
        "outputId": "60c28c24-421d-4638-842a-981dcc87957b"
      },
      "source": [
        "gru2()#o is of len 8 and the last index is equal to h"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:6 out of the last 6 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f442ab56dd0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
            "output(o):  [[[ 0.00467877  0.03199442  0.3707914 ]\n",
            "  [ 0.27545723 -0.01628624  0.08544643]\n",
            "  [-0.06234656 -0.0585709   0.14355624]\n",
            "  [-0.40315416 -0.15214118 -0.41153377]\n",
            "  [ 0.2347648   0.01053613 -0.42079073]\n",
            "  [-0.04695862 -0.00293355 -0.52475184]\n",
            "  [-0.03138866  0.0814103   0.15198553]\n",
            "  [-0.28519148 -0.00955906  0.11908737]]]\n",
            "hidden(h):  [[-0.28519148 -0.00955906  0.11908737]]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}